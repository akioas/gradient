!apt-get update
!apt-get install fonts-dejavu-core fonts-liberation ttf-mscorefonts-installer -y


import numpy as np
from PIL import Image, ImageDraw, ImageFont
import os
import random
from matplotlib.font_manager import FontProperties

# Шаг 1. Подготовить обучающую выборку, каждый элемент которой будет
#состоять из пар (X, D)m (m=1,…q) – обучающего вектора Xm = (x1,…,xn) (i=1,…,n) с
#вектором желаемых значений Dm = (d1,…,dk) (j=1,…,k) выходов персептрона.

symbols = ['A', 'B', 'C', 'D']

font_paths = [
'/usr/share/fonts/truetype/humor-sans/Humor-Sans.ttf',
'/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf',
'/usr/share/fonts/truetype/liberation/LiberationSerif-Italic.ttf',
'/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf',
'/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf'
]

img_size = (28, 28)

def generate_symbol_image(char, font_path):
  system_font_path = font_path
  font = ImageFont.truetype(system_font_path, 24)
  img = Image.new('L', img_size, color=255)
  draw = ImageDraw.Draw(img)
  pos = ((img_size[0] - 24) // 2, (img_size[1] - 24) // 2)
  draw.text(pos, char, fill=0, font=font)
  return np.array(img).flatten() / 255.0
X_train = []
D_train = []

for label, char in enumerate(symbols):
    for font in font_paths[:4]:  
        vector = generate_symbol_image(char, font)
        X_train.append(vector)
        one_hot = [0] * 4
        one_hot[label] = 1
        D_train.append(one_hot)

X_train = np.array(X_train)
D_train = np.array(D_train)

X_test = []
D_test = []

for label, char in enumerate(symbols):
    vector = generate_symbol_image(char, font_paths[4])
    X_test.append(vector)
    one_hot = [0] * 4
    one_hot[label] = 1
    D_test.append(one_hot)

X_test = np.array(X_test)
D_test = np.array(D_test)
# Шаг 2. Генератором случайных чисел всем синаптическим весам wi,j и
#нейронным смещениям w0,j (i=0,…,n; j=1,…,k) присваиваются некоторые малые
#случайные значения.
n = X_train.shape[1]  
k = D_train.shape[1]  
weights = np.random.uniform(-0.2, 0.2, size=(k, n + 1))
learning_rate = 0.2
epochs = 1000
tol = 1e-3
q = X_train.shape[0]


# Шаг 3. Общей ошибке Eобщ, вычисляемой на всех обучающих образах и всем
#значениям коррекции синаптических весов ∆wi,j присвоить нулевое значение.

for epoch in range(epochs):
    E_total = 0
    delta_w_total = np.zeros_like(weights)
# Шаг 4. Из обучающей выборки (X, D)1,…,(X, D)q, взять следующий по счету
#вектор Xт = (x1,…,xn) и подать его на входы персептрона x1,…,xn. Сигналам
#нейронных входов смещения x0 присваиваются единичные значения: x0 = 1.
    for m in range(q):
        x_m = np.insert(X_train[m], 0, 1)  # добавляем x0 = 1
        d_m = D_train[m]  # вектор длины 4

# Шаг 5. Для каждого j-го нейрона вычислить взвешенную сумму входных
#сигналов netj и выходной сигнал yj на основании функции активации f
        net = np.dot(weights, x_m) 
      
        y = 1 / (1 + np.exp(-net))
  



# Шаг 6. Вычислить ошибку E для текущего обучающего вектора и сложить
#полученное значение с общей ошибкой Eобщ  
        E = 0.5 * np.sum((d_m - y) ** 2)
        E_total += E
#Шаг 7. Посчитать величину коррекции синаптических весов j-го нейрона и
#нейронных смещений и запомнить их (накопление изменений)
        delta = -(d_m - y) * y * (1 - y)  
        delta_w = np.outer(delta, x_m)  
        delta_w_total += delta_w
#Шаг 8. После подачи последнего обучающего вектора (завершения эпохи),
#проверить критерий останова обучения, если он выполняется, то завершить
#обучение. В противном случае – выполнить шаг 9, после чего вернуться к шагу 3
    if E_total / q < tol:
        print(f"\nОбучение остановлено на эпохе {epoch+1}, средняя ошибка: {E_total/q:.6f}")
        break
#Шаг 9. Произвести коррекцию синаптических весов j-го нейрона и нейронных
#смещений по сохраненным (накопленным) значениям ∆wi,j
    weights -= learning_rate * delta_w_total / q

    if epoch % 100 == 0 or epoch == epochs - 1:
        print(f"Эпоха {epoch+1}, ошибка: {E_total/q:.6f}")

print("Финальные веса:", weights)

def predict(x):
    x_bias = np.insert(x, 0, 1)
    net = np.dot(weights, x_bias)
    y = 1 / (1 + np.exp(-net))
    return np.argmax(y)

correct = 0
for i in range(len(X_test)):
    pred = predict(X_test[i])
    true = np.argmax(D_test[i])
    print(f"Образец {i+1}: Правильный: {symbols[true]}, Предсказано: {symbols[pred]}")
    if pred == true:
        correct += 1

accuracy = correct / len(X_test)
print(f"\nТочность на тестовой выборке: {accuracy:.2%}")
