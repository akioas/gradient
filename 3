from tensorflow.keras.datasets import fashion_mnist 
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.utils import to_categorical 
(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()
x_train = x_train.reshape(x_train.shape[0], -1) / 255.0 
x_test = x_test.reshape(x_test.shape[0], -1) / 255.0
y_train = to_categorical(y_train) 
y_test = to_categorical(y_test)
model = Sequential()
model.add(Dense(10, input_dim=784, activation='relu'))
model.add(Dense(10, activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.fit(x_train, y_train, epochs=10, validation_split=0.1)
_, test_acc = model.evaluate(x_test, y_test) 
print(test_acc)
model2 = Sequential()
model2.add(Dense( 50, input_dim=784, activation='relu')) 
model2.add(Dense(10, activation='softmax')) 
model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model2.fit(x_train, y_train, epochs=10, validation_split=0.1)
model3 = Sequential()
model3.add(Dense(50, input_dim=784, activation='relu')) 
model3.add(Dense(50, activation='relu'))
model3.add(Dense(10, activation='softmax')) 
model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model3.fit(x_train, y_train, epochs=10, validation_split=0.1)

from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten 
import numpy as np
(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data() 
x_train = x_train[:,:,:,np.newaxis] / 255.0
x_test = x_test[:,:,:,np.newaxis] / 255.0
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)
model4 = Sequential()
model4.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28, 1))) 
model4.add(MaxPooling2D(pool_size=2))
model4.add(Flatten())
model4.add(Dense(10, activation='softmax')) 
model4.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model4.fit(x_train, y_train, epochs=10, validation_split=0.1)



##################


import numpy as np

input_size = 3    
hidden_size = 4   
output_size = 3 
lr = 0.4         
epochs = 10000    
tol = 1e-4        

X = np.array([0.4, -0.7, 1.3])
Y = np.array([0.3, -0.5, 0.8])

np.random.seed()
W1 = np.random.uniform(-0.3, 0.3, (hidden_size, input_size + 1))  
W2 = np.random.uniform(-0.3, 0.3, (output_size, hidden_size + 1))

def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def sigmoid_derivative(x):
    return x * (1 - x)

for epoch in range(epochs):
    x_b = np.insert(X, 0, 1)  
    net_h = np.dot(W1, x_b)
    out_h = sigmoid(net_h)
    out_h_b = np.insert(out_h, 0, 1) 

    net_o = np.dot(W2, out_h_b)
    out_o = sigmoid(net_o)

    error = Y - out_o
    E_total = np.sum(error**2) / 2

    if E_total < tol:
        print(f"Обучение завершено на эпохе {epoch}, ошибка: {E_total:.6f}")
        break

    delta_o = error * sigmoid_derivative(out_o)
    delta_h = sigmoid_derivative(out_h) * np.dot(W2[:, 1:].T, delta_o)

    W2 += lr * np.outer(delta_o, out_h_b)
    W1 += lr * np.outer(delta_h, x_b)

    if epoch % 500 == 0:
        print(f"Эпоха {epoch}: ошибка = {E_total:.6f}")

print("Предсказание:", out_o)
print("Эталонный выход:", Y)
print("Ошибка:", np.round(Y - out_o, 4))
